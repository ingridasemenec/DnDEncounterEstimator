{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code to take a peak at the data structure\n",
    "\n",
    "file_path = 'C:/Erdos/Project/DnDFireballProject/anonymized/data/1669407306-9f1295bf-4615-43d8-beab-b2027cb3ed97.jsonl.gz'\n",
    "\n",
    "logs = []\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            event = json.loads(line)\n",
    "            if event.get(\"event_type\") == \"combat_state_update\":\n",
    "                combat = event.get(\"data\")\n",
    "                for actor in combat.get(\"combatants\", []):\n",
    "                    if actor[\"type\"] == \"monster\":\n",
    "                        logs.append(actor)\n",
    "                        \n",
    "logs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'1669407306-9f1295bf-4615-43d8-beab-b2027cb3ed97': {'start_time': 1669407306.4081872,\n",
       "              'player_ids': {'127363826277379389',\n",
       "               '137220621341913368',\n",
       "               '139194158998008781',\n",
       "               '319173686662838782',\n",
       "               '812784442415776715'},\n",
       "              'player_info': {'Zara': {'hp_ratio': [433, 462],\n",
       "                'class': [('Warlock', 19)]},\n",
       "               'Hugh': {'hp_ratio': [334, 367],\n",
       "                'class': [('Paladin', 16), ('Barbarian', 4)]},\n",
       "               'Shirea': {'hp_ratio': [157, 257], 'class': [('Fighter', 18)]},\n",
       "               'Prince': {'hp_ratio': [194, 194], 'class': [('Fighter', 19)]},\n",
       "               'Neel Aoi': {'hp_ratio': [99, 141],\n",
       "                'class': [('Paladin', 11), ('Warlock', 7)]}},\n",
       "              'monsters': [{'monster_id': '2c508b97-cb05-4637-87bd-9ec82c73b0c4',\n",
       "                'monster_code': 'KR2',\n",
       "                'monster_name': 'Kraken',\n",
       "                'level': 23.0},\n",
       "               {'monster_id': 'e72adb42-4621-4482-8e45-67636d6af29e',\n",
       "                'monster_code': 'KR1',\n",
       "                'monster_name': 'Kraken',\n",
       "                'level': 23.0}]}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main function that parses each combat session\n",
    "\n",
    "from collections import defaultdict\n",
    "combat_data = defaultdict(lambda: {\n",
    "     'start_time': None, \n",
    "     'player_ids': set(),\n",
    "     'player_info': {} \n",
    "})\n",
    "def process_file(file_path):\n",
    "    monsters_found = False\n",
    "    players_found = False\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            event = json.loads(line)\n",
    "            if event.get(\"event_type\") == \"combat_state_update\":\n",
    "                combat = event.get(\"data\")\n",
    "                for actor in combat.get(\"combatants\", []):\n",
    "                    if actor[\"type\"] == \"monster\":\n",
    "                        monsters_found = True\n",
    "                    elif actor[\"type\"] == \"player\":\n",
    "                        players_found = True\n",
    "                    if monsters_found and players_found:\n",
    "                        break  # Break from the inner loop if both found\n",
    "                if monsters_found and players_found:\n",
    "                    break  # Break from the outer loop if both found\n",
    "\n",
    "    # If no monsters or players were found, return immediately\n",
    "    if not monsters_found or not players_found:\n",
    "        return None  # Or an appropriate indicator that the file was skipped\n",
    "    \n",
    "    \n",
    "\n",
    "    last_human_readable = {}\n",
    "\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            event = json.loads(line)\n",
    "            combat_id = event.get(\"combat_id\")\n",
    "\n",
    "            # Checking for combat start and getting timestamp (dont think we actually need timestamp)\n",
    "            if event.get(\"event_type\") == \"combat_start\":\n",
    "                combat_data[combat_id]['start_time'] = event.get(\"timestamp\")\n",
    "\n",
    "            # counting players who joined initiative\n",
    "            elif event.get(\"event_type\") == \"command\" and event.get(\"command_name\") == \"init join\":\n",
    "                player_id = event.get(\"author_id\")\n",
    "                player_name = event.get(\"caster\", {}).get(\"name\", event.get(\"author_name\"))\n",
    "                combat_data[combat_id]['player_ids'].add(player_id)\n",
    "                combat_data[combat_id]['player_info'][player_name] = {'hp_ratio': None}\n",
    "                classes_dict = event['caster']['levels']['classes']\n",
    "                combat_data[combat_id]['player_info'][player_name]['class'] = list(classes_dict.items())\n",
    "\n",
    "\n",
    "            elif event.get(\"event_type\") == \"combat_state_update\":\n",
    "                combat = event.get(\"data\")\n",
    "                for actor in combat.get(\"combatants\", []):\n",
    "                    if actor[\"type\"] == \"monster\":\n",
    "                        # Ensure 'monsters' is initialized as a list if it doesn't already exist\n",
    "                        if 'monsters' not in combat_data[combat_id]:\n",
    "                            combat_data[combat_id]['monsters'] = []\n",
    "\n",
    "                        # Define a helper function to check if the monster is already added\n",
    "                        def monster_exists(monster_list, monster_id):\n",
    "                            return any(monster['monster_id'] == monster_id for monster in monster_list)\n",
    "\n",
    "                        # Check if this monster is already added, to avoid duplication\n",
    "                        if not monster_exists(combat_data[combat_id]['monsters'], actor[\"id\"]):\n",
    "                            # If the monster is not in the list, add it with all its details\n",
    "                            combat_data[combat_id]['monsters'].append({\n",
    "                                'monster_id': actor[\"id\"],\n",
    "                                'monster_code': actor[\"name\"],\n",
    "                                'monster_name': actor['monster_name'],\n",
    "                                'level': actor['levels']['total_level']\n",
    "                            })\n",
    "\n",
    "\n",
    "                #trying to get that human readable part\n",
    "                human_readable = event.get(\"human_readable\")\n",
    "\n",
    "                if human_readable:\n",
    "                    last_human_readable[combat_id] = human_readable\n",
    "  \n",
    "    # Grab player names from combat_data dictionary\n",
    "    player_names = ', '.join(str(key) for key in combat_data[combat_id]['player_info'].keys())\n",
    "    if len(player_names) != 0:\n",
    "        player_names = player_names.split(',')\n",
    "        player_names = [name.lstrip() for name in player_names]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    if last_human_readable[combat_id]:\n",
    "        # print(last_human_readable[combat_id])\n",
    "\n",
    "        # Iterating through player names and finding their health in the human_readable string\n",
    "        if len(player_names) != 0:\n",
    "            for player in player_names:\n",
    "                try: \n",
    "                    pattern = rf\"{player} <(\\d+)/(\\d+) HP>\"\n",
    "\n",
    "                    match = re.search(pattern, last_human_readable[combat_id])\n",
    "\n",
    "                    if match:\n",
    "                        current_hp, max_hp = match.groups()\n",
    "\n",
    "                        if player in combat_data[combat_id]['player_info'] and current_hp and max_hp:\n",
    "                            combat_data[combat_id]['player_info'][player]['hp_ratio'] = [int(current_hp), int(max_hp)]\n",
    "                        else:\n",
    "                            continue\n",
    "                except re.error:\n",
    "                    print(f\"Skipping due to an error with pattern: {pattern}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "#     # Processing the last human_readable to extract HP ratios (this is not working ....)\n",
    "#     for cid, human_readable in last_human_readable.items():\n",
    "#         pattern = r'\\d+: ([\\w\\s.-]+) <(\\d+/\\d+ HP)>'\n",
    "#         matches = re.findall(pattern, human_readable)\n",
    "\n",
    "#         for name, hp_ratio in matches:\n",
    "#             if name in combat_data[cid]['player_info']:\n",
    "#                 combat_data[cid]['player_info'][name]['hp_ratio'] = hp_ratio\n",
    "\n",
    "#     # Printing the last human_readable string for each combat ID\n",
    "#     for cid, human_readable in last_human_readable.items():\n",
    "#         print(f\"Last 'human_readable' for {cid}: {human_readable}\")\n",
    "\n",
    "    # # Creating the DataFrame from collected data\n",
    "    # processed_data = []\n",
    "    # for cid, data in combat_data.items():\n",
    "    #     processed_data.append({\n",
    "    #         \"combat_id\": cid,\n",
    "    #         \"start_time\": data['start_time'],\n",
    "    #         \"num_player_actors\": len(data['player_ids']),\n",
    "    #         \"player_info\": data['player_info'],\n",
    "    #         \"num_monster_actors\": len(data['monster_ids']),\n",
    "    #         \"monster_ids\": list(data['monster_ids']),\n",
    "    #         \"monster_names\": list(data['monster_names']),\n",
    "    #     })\n",
    "\n",
    "    # return pd.DataFrame(processed_data)\n",
    "    return combat_data\n",
    "    \n",
    "# Define a file path\n",
    "file_path = 'C:/Erdos/Project/DnDFireballProject/anonymized/data/1669407306-9f1295bf-4615-43d8-beab-b2027cb3ed97.jsonl.gz'\n",
    "\n",
    "# Process the file and create DataFrame\n",
    "combat_data = process_file(file_path)\n",
    "\n",
    "# # Export to CSV\n",
    "# csv_file_path = 'C:/Users/josep/OneDrive/Desktop/Erdos/anonymized/data/combat_analysis_with_hp.csv'\n",
    "# df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# print(f\"Data exported to CSV file at: {csv_file_path}\")\n",
    "\n",
    "combat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 5000/5000 [02:55<00:00, 28.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function that takes the above function and iterates it over a directory of files\n",
    "\n",
    "directory_path = 'C:\\\\Erdos\\\\Project\\\\data'\n",
    "files = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.jsonl.gz')]\n",
    "files = files[:5000]\n",
    "def process_combat_files(file_paths):\n",
    "    combat_datas = {}  # This will store the combined data from all files\n",
    "\n",
    "    for file_path in tqdm(file_paths, desc=\"Processing files\"):\n",
    "        # Process each file to get its combat data\n",
    "        combat_data_latest = process_file(file_path)\n",
    "        \n",
    "        # If combat_data_latest is None (file was skipped), continue to the next file\n",
    "        if combat_data_latest is None:\n",
    "            continue\n",
    "\n",
    "        # Merge the data into combat_datas\n",
    "        # Assuming combat_data_latest contains data keyed by combat_id\n",
    "        for combat_id, data in combat_data_latest.items():\n",
    "            if combat_id in combat_datas:\n",
    "                # If combat_id already exists, merge or update data as needed\n",
    "                # This part depends on how you want to handle duplicate combat_ids\n",
    "                # For simplicity, let's just update the existing data with the new one\n",
    "                combat_datas[combat_id].update(data)\n",
    "            else:\n",
    "                # Add the new combat_id and its data to combat_datas\n",
    "                combat_datas[combat_id] = data\n",
    "\n",
    "    return combat_datas\n",
    "\n",
    "\n",
    "final_combat_data = process_combat_files(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': 1656527597.5520818,\n",
       " 'player_ids': {'163631059791733886'},\n",
       " 'player_info': {'Elias Varkin': {'hp_ratio': [0, 201],\n",
       "   'class': [('Rogue', 18)]}},\n",
       " 'monsters': [{'monster_id': 'c1fe0ab0-fe0e-4272-8d72-d7d3bc7e59c2',\n",
       "   'monster_code': 'CY1',\n",
       "   'monster_name': 'Cyclops',\n",
       "   'level': 6.0},\n",
       "  {'monster_id': '91b90566-dea8-46e3-8d99-e86677370d71',\n",
       "   'monster_code': 'CY2',\n",
       "   'monster_name': 'Cyclops',\n",
       "   'level': 6.0},\n",
       "  {'monster_id': '1f61ddbc-6b93-481d-9d9d-6891f2fa62e2',\n",
       "   'monster_code': 'SB3',\n",
       "   'monster_name': 'Sahuagin Baron',\n",
       "   'level': 5.0},\n",
       "  {'monster_id': 'cb4863a7-8a4e-481a-833c-7f016c969e47',\n",
       "   'monster_code': 'SB2',\n",
       "   'monster_name': 'Sahuagin Baron',\n",
       "   'level': 5.0},\n",
       "  {'monster_id': '09805004-bf91-49b4-8024-c19b2da391d8',\n",
       "   'monster_code': 'SB4',\n",
       "   'monster_name': 'Sahuagin Baron',\n",
       "   'level': 5.0},\n",
       "  {'monster_id': '72471b83-0afc-4a78-ab14-ae590ed8eb68',\n",
       "   'monster_code': 'SB1',\n",
       "   'monster_name': 'Sahuagin Baron',\n",
       "   'level': 5.0}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_combat_data[list(final_combat_data.keys())[np.random.randint(0,len(final_combat_data))]] # Randomly selecting an item from the list to see if the function is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Assuming final_combat_data is your dictionary that might contain sets\n",
    "with open('combat_data.yaml', 'w', encoding='utf-8') as yaml_file:\n",
    "    yaml.dump(final_combat_data, yaml_file, default_flow_style=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the YAML file back into a dictionary\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombat_data.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n\u001b[1;32m----> 5\u001b[0m     loaded_dict \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(yaml_file, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mFullLoader)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Now loaded_dict contains your dictionary\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mlen\u001b[39m(loaded_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[1;34m(stream, Loader)\u001b[0m\n\u001b[0;32m     79\u001b[0m loader \u001b[38;5;241m=\u001b[39m Loader(stream)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mget_single_data()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     loader\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_single_node()\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[1;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_document()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, item_key)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, item_key)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "    \u001b[1;31m[... skipping similar frames: Composer.compose_mapping_node at line 133 (2 times), Composer.compose_node at line 84 (2 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_mapping_node(anchor)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, item_key)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\composer.py:64\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent, index):\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(AliasEvent):\n\u001b[0;32m     65\u001b[0m         event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_event()\n\u001b[0;32m     66\u001b[0m         anchor \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39manchor\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[1;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate()\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\parser.py:451\u001b[0m, in \u001b[0;36mParser.parse_block_mapping_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(KeyToken, ValueToken, BlockEndToken):\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_mapping_key)\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_node_or_indentless_sequence()\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_block_mapping_key\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\parser.py:271\u001b[0m, in \u001b[0;36mParser.parse_block_node_or_indentless_sequence\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_block_node_or_indentless_sequence\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_node(block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, indentless_sequence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\parser.py:319\u001b[0m, in \u001b[0;36mParser.parse_node\u001b[1;34m(self, block, indentless_sequence)\u001b[0m\n\u001b[0;32m    317\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    318\u001b[0m implicit \u001b[38;5;241m=\u001b[39m (tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m tag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indentless_sequence \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_token(BlockEntryToken):\n\u001b[0;32m    320\u001b[0m     end_mark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeek_token()\u001b[38;5;241m.\u001b[39mend_mark\n\u001b[0;32m    321\u001b[0m     event \u001b[38;5;241m=\u001b[39m SequenceStartEvent(anchor, tag, implicit,\n\u001b[0;32m    322\u001b[0m             start_mark, end_mark)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yaml\\scanner.py:121\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens[\u001b[38;5;241m0\u001b[39m], choice):\n\u001b[0;32m    122\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Load the YAML file back into a dictionary\n",
    "with open('combat_data.yaml', 'r', encoding='utf-8') as yaml_file:\n",
    "    loaded_dict = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Now loaded_dict contains your dictionary\n",
    "len(loaded_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
