{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import ast\n",
    "import gzip\n",
    "import os\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_std_player_classes_monsters(df):\n",
    "    # Convert the list of standard classes to a set for faster membership checks\n",
    "    standard_classes = {\n",
    "        'Barbarian', 'Bard', 'Cleric', 'Druid', 'Fighter', 'Monk', \n",
    "        'Paladin', 'Ranger', 'Rogue', 'Sorcerer', 'Warlock', 'Wizard', 'Blood Hunter'\n",
    "    }\n",
    "\n",
    "    def are_all_classes_standard(player_list_str):\n",
    "        # Convert the string representation of the list only once\n",
    "        player_list = ast.literal_eval(player_list_str)\n",
    "        for player in player_list:\n",
    "            # Iterate through each class information tuple\n",
    "            for class_info in player['class']:\n",
    "                # Check against the set of standard classes\n",
    "                if class_info[0].strip() not in standard_classes:\n",
    "                    return False\n",
    "        return True\n",
    "    \n",
    "    # Filter rows based on player_info\n",
    "    tqdm.pandas(desc=\"Filtering Players\")\n",
    "    df_filtered = df[df['player_info'].progress_apply(are_all_classes_standard)]\n",
    "    \n",
    "    # Filter rows based on monsters_info\n",
    "    df_filtered = df_filtered[df_filtered['monsters_info'] != \"[]\"]\n",
    "\n",
    "    # Filter rows based on party total hpratio\n",
    "    df_filtered = df_filtered.dropna(subset=['party_total_hpratio'])\n",
    "    \n",
    "    # Filter rows based on party_total_precombat_hp\n",
    "    df_filtered = df_filtered[df_filtered['party_total_precombat_hp']<1e10]\n",
    "\n",
    "    # Filter rows based on party_total_precombat_hp\n",
    "    df_filtered = df_filtered[df_filtered['party_total_postcombat_hp']<1e10]\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combat_data_df = pd.read_csv(\"filtered_combat_data_df_04-01.csv\")\n",
    "print(combat_data_df.shape)\n",
    "\n",
    "# combat_data_filtered_df = filter_std_player_classes_monsters(combat_data_df)\n",
    "# print(combat_data_filtered_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_path = './filtered_combat_data_df_04-01.csv'\n",
    "# combat_data_filtered_df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./filtered_combat_data_df_04-01.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# df = combat_data_filtered_df\n",
    "# # Display the first few rows of the dataset\n",
    "# display(df.head())\n",
    "# # Display summary statistics\n",
    "# display(df.describe())\n",
    "# # Check for missing values\n",
    "# #display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "\n",
    "filtered = df.copy()\n",
    "\n",
    "# Dropping party sizes below 10\n",
    "filtered = filtered[filtered['party_size'] < 10]\n",
    "\n",
    "\n",
    "rows_to_drop = []\n",
    "\n",
    "# Dropping levels above 20\n",
    "for index, row in filtered.iterrows():\n",
    "    player_info = ast.literal_eval(row['player_info'])\n",
    "    for d in player_info:\n",
    "        total_lvl = sum(class_lvl[1] for class_lvl in d['class'])\n",
    "        if total_lvl > 20:\n",
    "            rows_to_drop.append(index)\n",
    "            break  # No need to check further dicts in this row\n",
    "\n",
    "filtered = filtered.drop(rows_to_drop)\n",
    "\n",
    "\n",
    "rows_to_drop = []\n",
    "\n",
    "# Droping those with either no hp ratio or hp's above 350\n",
    "for index, row in filtered.iterrows():\n",
    "    player_info = ast.literal_eval(row['player_info'])\n",
    "    for d in player_info:\n",
    "        # Corrected the check for None\n",
    "        if d['hp_ratio'] is None:\n",
    "            rows_to_drop.append(index)  # Appending index for consistency\n",
    "            break  # Exit the loop after finding the condition met\n",
    "        else:\n",
    "            max_health = d['hp_ratio'][1]\n",
    "            if max_health > 350:\n",
    "                rows_to_drop.append(index)\n",
    "                break  # No need to check further dicts in this row\n",
    "\n",
    "\n",
    "rows_to_drop = []\n",
    "\n",
    "# Dropping those either with no AC value(s) or AC's above 38\n",
    "for index, row in filtered.iterrows():\n",
    "    player_info = ast.literal_eval(row['player_info'])\n",
    "    for d in player_info:\n",
    "        # Corrected the check for None\n",
    "        if d['ac'] is None:\n",
    "            rows_to_drop.append(index)  # Appending index for consistency\n",
    "            break  # Exit the loop after finding the condition met\n",
    "        else:\n",
    "            ac = d['ac']\n",
    "            if ac > 38:\n",
    "                rows_to_drop.append(index)\n",
    "                break  # No need to check further dicts in this row\n",
    "\n",
    "\n",
    "filtered = filtered.drop(rows_to_drop)\n",
    "\n",
    "\n",
    "# Dropping who either do not have an ability score or if an ability score is above 22\n",
    "stats = ['strength', 'dexterity', 'constitution', 'intelligence', 'wisdom', 'charisma']\n",
    "\n",
    "rows_to_drop = []\n",
    "for index, row in filtered.iterrows():\n",
    "    player_info = ast.literal_eval(row['player_info'])\n",
    "    for d in player_info:\n",
    "        # Check if 'stats' is None\n",
    "        if d['stats'] is None:\n",
    "            rows_to_drop.append(index)  # Appending index for consistency\n",
    "            break  # Exit the loop after finding the condition met\n",
    "        else:\n",
    "            # Iterate over the items in the 'stats' dictionary\n",
    "            for key, value in d['stats'].items():\n",
    "                if key in stats and value > 22:\n",
    "                    rows_to_drop.append(index)\n",
    "                    break  # Exit the loop after finding a stat greater than 22\n",
    "\n",
    "\n",
    "filtered = filtered.drop(rows_to_drop)\n",
    "\n",
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding player to monster and monster to player ratios \n",
    "filtered['player_monster_ratio'] = filtered['party_size']/filtered['monster_number']\n",
    "\n",
    "filtered['monster_player_ratio'] = filtered['monster_number']/filtered['party_size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file_path = './filtered_combat_data_df_04-01.csv'\n",
    "filtered.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = filtered.select_dtypes(include=['int64', 'float64']).columns.drop(['start_time'])\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Histograms for numerical features\n",
    "for feature in num_features:\n",
    "    try:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.histplot(filtered[feature], kde=True)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(f\"Failed {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correlation heatmap for numerical features including sessions with no damage\n",
    "corr = filtered[num_features].corr()\n",
    "corr_filled = corr#corr.fillna(0)\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr_filled, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap (Sessions without Damage Included)')\n",
    "plt.savefig(\"corr_no_dmg_included.png\", format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# Attempt to convert the string representation of lists in 'party_classes_with_level' into actual lists\n",
    "# Note: We'll need to be cautious since this column contains complex data structures (lists of tuples).\n",
    "\n",
    "# Sample conversion to check the format and ensure our method works\n",
    "sample_composition = literal_eval(df['party_classes_with_level'][0])\n",
    "\n",
    "# For demonstration, let's process the first few rows to see the data we're working with\n",
    "df['party_composition_parsed'] = df['party_classes_with_level'].apply(literal_eval)\n",
    "\n",
    "# Now, let's create a simplified representation: count of each class in a combat\n",
    "# This is a simplification. A more detailed analysis might consider levels, or the presence of specific classes.\n",
    "def simplify_composition(composition):\n",
    "    class_count = {}\n",
    "    for class_level in composition:\n",
    "        class_name = class_level[0]  # Extract class name\n",
    "        if class_name in class_count:\n",
    "            class_count[class_name] += 1\n",
    "        else:\n",
    "            class_count[class_name] = 1\n",
    "    return class_count\n",
    "\n",
    "df['simple_composition'] = df['party_composition_parsed'].apply(simplify_composition)\n",
    "\n",
    "# Let's take a look at what this simplified composition looks like for the first few entries\n",
    "df[['party_composition_parsed', 'simple_composition', 'party_total_hpratio']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To proceed with the analysis, we'll group the data by the simplified compositions and calculate the average HP ratio.\n",
    "# Given the complexity of using the simplified composition (a dictionary) directly for grouping, we'll instead use a string representation of it.\n",
    "# This approach simplifies the grouping but loses some granularity (e.g., different compositions with the same classes in different quantities will be treated the same).\n",
    "\n",
    "# Convert the simple_composition dictionaries to sorted strings for consistent grouping\n",
    "df['composition_str'] = df['simple_composition'].apply(lambda x: str(sorted(x.items())))\n",
    "\n",
    "# Group by these composition strings and calculate the average HP ratio for each\n",
    "composition_success = df.groupby('composition_str')['party_total_hpratio'].agg(['mean', 'count', 'std']).reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "composition_success.columns = ['Composition', 'Average_HP_Ratio', 'Encounter_Count', 'HP_Ratio_STD']\n",
    "\n",
    "# Sort the results by the average HP ratio in descending order to see the most successful compositions\n",
    "# We also filter for compositions encountered more than once for more reliable insights\n",
    "composition_success_filtered = composition_success[composition_success['Encounter_Count'] > 1].sort_values(by='Average_HP_Ratio', ascending=False)\n",
    "\n",
    "# composition_success_filtered.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.simple_composition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
